{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OfUmXr1D1ZSR"
   },
   "source": [
    "# Key-Value Attention for Thai Karaoke Character-level Machine Translation (Many-to-Many, encoder-decoder)\n",
    "\n",
    "In this homework, you will create an MT model with attention mechnism that coverts names of Thai 2019 MP candidates from Thai script to Roman(Latin) script. E.g. นิยม-->niyom\n",
    "\n",
    "The use of Pytorch Lightning is optional but recommended. You can use Pytorch if you prefer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T17:59:14.948637Z",
     "iopub.status.busy": "2025-01-25T17:59:14.948384Z",
     "iopub.status.idle": "2025-01-25T17:59:20.640884Z",
     "shell.execute_reply": "2025-01-25T17:59:20.640111Z",
     "shell.execute_reply.started": "2025-01-25T17:59:14.948606Z"
    },
    "id": "18KMSkqZ-Pt-",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip install lightning wandb\n",
    "# !wget https://github.com/Phonbopit/sarabun-webfont/raw/master/fonts/thsarabunnew-webfont.ttf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T17:59:20.641954Z",
     "iopub.status.busy": "2025-01-25T17:59:20.641744Z",
     "iopub.status.idle": "2025-01-25T17:59:20.743140Z",
     "shell.execute_reply": "2025-01-25T17:59:20.742383Z",
     "shell.execute_reply.started": "2025-01-25T17:59:20.641935Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# from kaggle_secrets import UserSecretsClient\n",
    "# user_secrets = UserSecretsClient()\n",
    "# wandb_api_key = user_secrets.get_secret(\"wandb_api_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-01-25T17:59:20.744417Z",
     "iopub.status.busy": "2025-01-25T17:59:20.744111Z",
     "iopub.status.idle": "2025-01-25T17:59:28.805846Z",
     "shell.execute_reply": "2025-01-25T17:59:28.805177Z",
     "shell.execute_reply.started": "2025-01-25T17:59:20.744387Z"
    },
    "id": "SKCBCWKARZEx",
    "outputId": "6ad8a585-fd68-44ee-deac-37143137cbcc",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !wandb login\n",
    "# import wandb\n",
    "# wandb.login(key=wandb_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T17:59:28.806971Z",
     "iopub.status.busy": "2025-01-25T17:59:28.806606Z",
     "iopub.status.idle": "2025-01-25T17:59:37.388396Z",
     "shell.execute_reply": "2025-01-25T17:59:37.387501Z",
     "shell.execute_reply.started": "2025-01-25T17:59:28.806950Z"
    },
    "id": "ka2TN8IV1ZSU",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "mpl.font_manager.fontManager.addfont('thsarabunnew-webfont.ttf') # 3.2+\n",
    "mpl.rc('font', family='TH Sarabun New')\n",
    "import torch\n",
    "# import torchtext\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import lightning as L\n",
    "import numpy as np\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-f_s6vX1ZSZ"
   },
   "source": [
    "## Load Dataset\n",
    "We have generated a toy dataset using names of Thai MP candidates in 2019 Thai General Election from elect.in.th's github(https://github.com/codeforthailand/dataset-election-62-candidates) and tltk (https://pypi.org/project/tltk/) library to convert them into Roman script.\n",
    "\n",
    "```\n",
    "ไกรสีห์ kraisi\n",
    "พัชรี phatri\n",
    "ธีระ thira\n",
    "วุฒิกร wutthikon\n",
    "ไสว sawai\n",
    "สัมภาษณ์  samphat\n",
    "วศิน wasin\n",
    "ทินวัฒน์ thinwat\n",
    "ศักดินัย sakdinai\n",
    "สุรศักดิ์ surasak\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-01-25T17:59:37.389700Z",
     "iopub.status.busy": "2025-01-25T17:59:37.389294Z",
     "iopub.status.idle": "2025-01-25T17:59:37.893280Z",
     "shell.execute_reply": "2025-01-25T17:59:37.892240Z",
     "shell.execute_reply.started": "2025-01-25T17:59:37.389678Z"
    },
    "id": "Jte-Csrf-4kd",
    "outputId": "a1ba364b-64c2-4875-873c-90bc1808a4be",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !wget https://raw.githubusercontent.com/ekapolc/nlp_2019/master/HW8/mp_name_th_en.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T17:59:37.896347Z",
     "iopub.status.busy": "2025-01-25T17:59:37.896105Z",
     "iopub.status.idle": "2025-01-25T17:59:37.910383Z",
     "shell.execute_reply": "2025-01-25T17:59:37.909684Z",
     "shell.execute_reply.started": "2025-01-25T17:59:37.896311Z"
    },
    "id": "L9zXp7KH1ZSa",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('mp_name_th_en.csv') as csvfile:\n",
    "    readCSV = csv.reader(csvfile, delimiter=',')\n",
    "    name_th = []\n",
    "    name_en = []\n",
    "    for row in readCSV:\n",
    "        temp_th = row[0]\n",
    "        temp_en = row[1]\n",
    "\n",
    "        name_th.append(temp_th)\n",
    "        name_en.append(temp_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T17:59:37.911920Z",
     "iopub.status.busy": "2025-01-25T17:59:37.911725Z",
     "iopub.status.idle": "2025-01-25T17:59:37.927215Z",
     "shell.execute_reply": "2025-01-25T17:59:37.926570Z",
     "shell.execute_reply.started": "2025-01-25T17:59:37.911903Z"
    },
    "id": "ZCsqrXxu1ZSe",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ไกรสีห์ kraisi\n",
      "พัชรี phatri\n",
      "ธีระ thira\n",
      "วุฒิกร wutthikon\n",
      "ไสว sawai\n",
      "สัมภาษณ์  samphat\n",
      "วศิน wasin\n",
      "ทินวัฒน์ thinwat\n",
      "ศักดินัย sakdinai\n",
      "สุรศักดิ์ surasak\n"
     ]
    }
   ],
   "source": [
    "for th, en in zip(name_th[:10],name_en[:10]):\n",
    "    print(th,en)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zvW8xqT81ZSh"
   },
   "source": [
    "## TODO1: Preprocess dataset\n",
    "* You will need 2 vocabularies (1 for input and another for output)\n",
    "* DON'T FORGET TO INCLUDE special token for padding (for both input and output)\n",
    "* DON'T FORGET TO INCLUDE special token for the end of word symbol (output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-01-25T17:59:37.928125Z",
     "iopub.status.busy": "2025-01-25T17:59:37.927896Z",
     "iopub.status.idle": "2025-01-25T17:59:37.946181Z",
     "shell.execute_reply": "2025-01-25T17:59:37.945493Z",
     "shell.execute_reply.started": "2025-01-25T17:59:37.928106Z"
    },
    "id": "_rv1Xd9A1ZSi",
    "outputId": "dece74ae-a492-41a7-f07d-2798157c7fcc",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10887 lines and 65 unique characters in your input data.\n"
     ]
    }
   ],
   "source": [
    "#Preprocessing\n",
    "input_chars = list(set(''.join(name_th)))\n",
    "output_chars = list(set(''.join(name_en)))\n",
    "data_size, vocab_size = len(name_th), len(input_chars)+1\n",
    "output_vocab_size = len(output_chars)+2#+2 for special end of sentence token/PADDING\n",
    "print('There are %d lines and %d unique characters in your input data.' % (data_size, vocab_size))\n",
    "maxlen = len( max(name_th, key=len)) #max input length\n",
    "maxlen_out = len( max(name_en, key=len)) #max input length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-01-25T17:59:37.947131Z",
     "iopub.status.busy": "2025-01-25T17:59:37.946897Z",
     "iopub.status.idle": "2025-01-25T17:59:37.958276Z",
     "shell.execute_reply": "2025-01-25T17:59:37.957646Z",
     "shell.execute_reply.started": "2025-01-25T17:59:37.947101Z"
    },
    "id": "mo381I_t1ZSm",
    "outputId": "4467516a-90c8-477d-bc43-bb071b17a956",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max input length: 20\n",
      "Max output length: 19\n"
     ]
    }
   ],
   "source": [
    "print(\"Max input length:\", maxlen)\n",
    "print(\"Max output length:\", maxlen_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T17:59:37.959369Z",
     "iopub.status.busy": "2025-01-25T17:59:37.959114Z",
     "iopub.status.idle": "2025-01-25T17:59:37.971093Z",
     "shell.execute_reply": "2025-01-25T17:59:37.970406Z",
     "shell.execute_reply.started": "2025-01-25T17:59:37.959341Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 24, 46, 23, 48, 26]\n",
      "ชนาธิป\n"
     ]
    }
   ],
   "source": [
    "sorted_chars= sorted(input_chars)\n",
    "sorted_output_chars= sorted(output_chars)\n",
    "sorted_chars.insert(0,\"<PAD>\") #PADDING for input\n",
    "sorted_output_chars.insert(0,\"<PAD>\") #PADDING for output\n",
    "sorted_output_chars.insert(1,\"</s>\")\n",
    "\n",
    "# Quick implementation of character tokenizer\n",
    "# create a mapping from characters to integers\n",
    "input_stoi = { ch:i for i,ch in enumerate(sorted_chars) }\n",
    "input_itos = { i:ch for i,ch in enumerate(sorted_chars) }\n",
    "input_encode = lambda s: [input_stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "input_decode = lambda l: ''.join([input_itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
    "\n",
    "\n",
    "output_stoi = { ch:i for i,ch in enumerate(sorted_output_chars) }\n",
    "output_itos = { i:ch for i,ch in enumerate(sorted_output_chars) }\n",
    "output_encode = lambda s: [output_stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "output_decode = lambda l: ''.join([output_itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
    "\n",
    "print(input_encode(\"ชนาธิป\"))\n",
    "print(input_decode(input_encode(\"ชนาธิป\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T17:59:37.972044Z",
     "iopub.status.busy": "2025-01-25T17:59:37.971833Z",
     "iopub.status.idle": "2025-01-25T17:59:38.267994Z",
     "shell.execute_reply": "2025-01-25T17:59:38.267289Z",
     "shell.execute_reply.started": "2025-01-25T17:59:37.972016Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10887, 20])\n",
      "torch.Size([10887, 19])\n"
     ]
    }
   ],
   "source": [
    "X = [torch.tensor(input_encode(list(name))) for name in name_th]\n",
    "Y = [torch.tensor(output_encode(list(name))) for name in name_en]\n",
    "X = nn.utils.rnn.pad_sequence(X, batch_first=True, padding_value=0)\n",
    "Y = nn.utils.rnn.pad_sequence(Y, batch_first=True, padding_value=0)\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T17:59:38.269055Z",
     "iopub.status.busy": "2025-01-25T17:59:38.268823Z",
     "iopub.status.idle": "2025-01-25T17:59:38.272945Z",
     "shell.execute_reply": "2025-01-25T17:59:38.271985Z",
     "shell.execute_reply.started": "2025-01-25T17:59:38.269033Z"
    },
    "id": "W3aXyJBEC-j_",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T17:59:38.273970Z",
     "iopub.status.busy": "2025-01-25T17:59:38.273707Z",
     "iopub.status.idle": "2025-01-25T17:59:38.285113Z",
     "shell.execute_reply": "2025-01-25T17:59:38.284364Z",
     "shell.execute_reply.started": "2025-01-25T17:59:38.273936Z"
    },
    "id": "-yirzlseC9NS",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class NameDataset(Dataset):\n",
    "  def __init__(self, X, y):\n",
    "    self.encoded = X.long()\n",
    "    self.label = y.long()\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return {\"x\" :self.encoded[idx], \"y\":self.label[idx]}\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T17:59:38.286092Z",
     "iopub.status.busy": "2025-01-25T17:59:38.285845Z",
     "iopub.status.idle": "2025-01-25T17:59:38.300022Z",
     "shell.execute_reply": "2025-01-25T17:59:38.299179Z",
     "shell.execute_reply.started": "2025-01-25T17:59:38.286072Z"
    },
    "id": "qUPAB7LTDFOy",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class NameDataModule(L.LightningDataModule):\n",
    "\n",
    "  def __init__(self, train_data, y, batch_size, num_workers=0):\n",
    "      super().__init__()\n",
    "      self.train_data = train_data\n",
    "      self.y = y\n",
    "      self.batch_size = batch_size\n",
    "      self.num_workers = num_workers\n",
    "\n",
    "\n",
    "  def setup(self, stage: str):\n",
    "    pass\n",
    "\n",
    "  def collate_fn(self, batch):\n",
    "    one_hot_x = torch.stack([F.one_hot(b[\"x\"], num_classes=len(input_stoi)) for b in batch])\n",
    "    return {\"x\": one_hot_x.float(), \"y\": torch.stack([b[\"y\"] for b in batch])}\n",
    "\n",
    "  def train_dataloader(self):\n",
    "    train_dataset = NameDataset(self.train_data, self.y)\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                                batch_size = self.batch_size,\n",
    "                                shuffle = True,\n",
    "                                collate_fn = self.collate_fn,\n",
    "                                num_workers = self.num_workers)\n",
    "    return train_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HFSG1FqK1ZSy"
   },
   "source": [
    "# Attention Mechanism\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HAlOrhbismQp"
   },
   "source": [
    "## TODO 2: Code your own (key-value) attention mechnism\n",
    "* PLEASE READ: you DO NOT have to follow all the details in (Daniluk, et al. 2017). You just need to create a key-value attention mechanism where the \"key\" part of the mechanism is used for attention score calculation, and the \"value\" part of the mechanism is used to encode information to create a context vector.  \n",
    "* fill code for one_step_attention function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T17:59:38.301182Z",
     "iopub.status.busy": "2025-01-25T17:59:38.300885Z",
     "iopub.status.idle": "2025-01-25T17:59:38.316105Z",
     "shell.execute_reply": "2025-01-25T17:59:38.315545Z",
     "shell.execute_reply.started": "2025-01-25T17:59:38.301136Z"
    },
    "id": "avnlc6p9BZDv",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def one_step_attention(h, s_prev, linear_1, linear_2, ):\n",
    "\n",
    "    #Split into Key-Value\n",
    "    key, value = torch.split(h, h.size(-1)//2, dim=-1)\n",
    "    #do concat with s_prev.\n",
    "    s_prev = s_prev.unsqueeze(1).repeat((1, key.shape[1], 1))\n",
    "    concat = torch.cat([key, s_prev], dim=-1) #concat.shape = batch, seq_len, hidden_dim*2\n",
    "    #hint: you will need to use s_prev.repeat(...) somehow so that it has the same dimension as the key\n",
    "    #hint2: s_prev.unsqueeze() could also be useful\n",
    "\n",
    "\n",
    "    #Attention function###\n",
    "    # use layer(s) from your model to calculate attention_scores and then softmax\n",
    "    # calculate a context vector\n",
    "    e = F.tanh(linear_1(concat))\n",
    "    energies = F.relu(linear_2(e))\n",
    "    attention_scores = F.softmax(energies, dim=1)\n",
    "    context = torch.mul(attention_scores, value) # (batch, seq_len, value_dim=hidden_dim_enc/2)\n",
    "    context = torch.sum(context, dim=1)\n",
    "    return context, attention_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6zWN02ZtuOIU"
   },
   "source": [
    "# Translation Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0phyUQYg1ZS8"
   },
   "source": [
    "## TODO3: Create and train your encoder/decoder model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T17:59:38.317273Z",
     "iopub.status.busy": "2025-01-25T17:59:38.316981Z",
     "iopub.status.idle": "2025-01-25T17:59:38.329049Z",
     "shell.execute_reply": "2025-01-25T17:59:38.328378Z",
     "shell.execute_reply.started": "2025-01-25T17:59:38.317240Z"
    },
    "id": "Ji_rUPhK1ZS9",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class AttentionModel(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        learning_rate=0.01,\n",
    "        criterion=nn.CrossEntropyLoss(),\n",
    "    ):\n",
    "\n",
    "        super().__init__()\n",
    "        self.n_h = 32 #hidden dimensions for encoder\n",
    "        self.n_s = 64 #hidden dimensions for decoder\n",
    "        self.learning_rate = learning_rate\n",
    "        self.criterion = criterion\n",
    "        #encoder can be any RNN of your choice\n",
    "        self.lstm = nn.LSTM(len(input_stoi), self.n_h, bidirectional=True, batch_first=True)\n",
    "        #decoder has to be (any) RNNCell since we will need to calculate attention for each timestep manually\n",
    "        self.decoder_lstm_cell = nn.LSTMCell(self.n_h, self.n_s)\n",
    "        self.output_layer = nn.Linear(self.n_s, len(output_stoi))\n",
    "        #attention\n",
    "        self.fc1 = nn.Linear(self.n_h + self.n_s, self.n_h)\n",
    "        self.fc2 = nn.Linear(self.n_h, 1)\n",
    "\n",
    "\n",
    "    def forward(self, src, return_attention=False): #use return_attention only when you want to get the attention scores for visualizing\n",
    "        #pass the input to the encoder\n",
    "        lstm_out, _ = self.lstm(src)\n",
    "        # print(lstm_out.shape)\n",
    "        #Initialize the LSTM states. We have to do this since we are using LSTMCell (https://pytorch.org/docs/stable/generated/torch.nn.LSTMCell.html)\n",
    "        #These states will get updated while we are decoding\n",
    "        decoder_s = torch.randn(src.shape[0], self.n_s).to(self.decoder_lstm_cell.weight_ih.device)\n",
    "        decoder_c = torch.randn(src.shape[0], self.n_s).to(self.decoder_lstm_cell.weight_ih.device)\n",
    "\n",
    "        #Iterate until max_output_length (Decoding)\n",
    "        prediction = torch.zeros((src.shape[0], maxlen_out, len(output_stoi))).to(self.decoder_lstm_cell.weight_ih.device)\n",
    "        attention_scores = [] #to store the score for each step\n",
    "        for t in range(maxlen_out):\n",
    "\n",
    "            #Perform one step of the attention mechanism to calculate the context vector at timestep t\n",
    "            context, attention_score = one_step_attention(lstm_out, decoder_s, self.fc1, self.fc2)\n",
    "            # print(context.shape, attention_score.shape)\n",
    "            attention_scores.append(attention_score)\n",
    "            # Feed the context vector to the decoder.\n",
    "            decoder_s, decoder_c = self.decoder_lstm_cell(context, (decoder_s, decoder_c))\n",
    "            # Pass the decoder hidden output to the output layer (softmax)\n",
    "            out = self.output_layer(decoder_s)\n",
    "            # Put the predicted output into the list for this timestep\n",
    "            prediction[:, t] = out\n",
    "\n",
    "        return (prediction, attention_scores if return_attention else None)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        src = batch['x']\n",
    "        target = batch['y']\n",
    "        prediction,_ = self(src)\n",
    "        prediction = prediction.reshape(-1, len(output_stoi))\n",
    "        target = target.reshape(-1)\n",
    "        loss = self.criterion(prediction, target)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        src = batch['x']\n",
    "        with torch.no_grad():\n",
    "          prediction, attention_scores = self(src, return_attention=True)\n",
    "          prediction = F.softmax(prediction, dim=-1)\n",
    "          prediction = torch.argmax(prediction, dim=-1)\n",
    "          for pred in prediction:\n",
    "            # TODO:\n",
    "            # print(\"\".join(output_stoi.lookup_tokens(pred.cpu().numpy())))\n",
    "            print(\"\".join(output_decode(pred.cpu().numpy())))\n",
    "        return prediction, attention_scores\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=self.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T18:37:50.126660Z",
     "iopub.status.busy": "2025-01-25T18:37:50.126342Z",
     "iopub.status.idle": "2025-01-25T18:37:50.134259Z",
     "shell.execute_reply": "2025-01-25T18:37:50.133246Z",
     "shell.execute_reply.started": "2025-01-25T18:37:50.126636Z"
    },
    "id": "pSM9dgDcCz1E",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = AttentionModel(\n",
    "    learning_rate=0.01,\n",
    "    criterion=nn.CrossEntropyLoss()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T18:37:51.513996Z",
     "iopub.status.busy": "2025-01-25T18:37:51.513654Z",
     "iopub.status.idle": "2025-01-25T18:37:51.518791Z",
     "shell.execute_reply": "2025-01-25T18:37:51.517734Z",
     "shell.execute_reply.started": "2025-01-25T18:37:51.513972Z"
    },
    "id": "RqrvmJalDLzF",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "batch_size = 2048\n",
    "data_module = NameDataModule(X, Y, batch_size, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T18:37:52.317643Z",
     "iopub.status.busy": "2025-01-25T18:37:52.317170Z",
     "iopub.status.idle": "2025-01-25T18:37:52.323404Z",
     "shell.execute_reply": "2025-01-25T18:37:52.322474Z",
     "shell.execute_reply.started": "2025-01-25T18:37:52.317604Z"
    },
    "id": "_sFjzKX8SECo",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from lightning import Trainer\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "wandb_logger = WandbLogger(project=\"hw3.1_attention\", name=\"run3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T18:37:52.915843Z",
     "iopub.status.busy": "2025-01-25T18:37:52.915557Z",
     "iopub.status.idle": "2025-01-25T18:37:52.963360Z",
     "shell.execute_reply": "2025-01-25T18:37:52.962549Z",
     "shell.execute_reply.started": "2025-01-25T18:37:52.915823Z"
    },
    "id": "OGWSzS-X1ZTO",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(\n",
    "    max_epochs=500,\n",
    "    logger=wandb_logger\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T18:37:54.835388Z",
     "iopub.status.busy": "2025-01-25T18:37:54.835040Z",
     "iopub.status.idle": "2025-01-25T18:39:01.497367Z",
     "shell.execute_reply": "2025-01-25T18:39:01.496633Z",
     "shell.execute_reply.started": "2025-01-25T18:37:54.835361Z"
    },
    "id": "7ZMi782c1ZTQ",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# trainer.fit(model, data_module)\n",
    "model = torch.load(\"att2048_500e.pth\")\n",
    "# model.load_state_dict(torch.load(\"att_1024.ckpt\")['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T18:39:05.460632Z",
     "iopub.status.busy": "2025-01-25T18:39:05.460237Z",
     "iopub.status.idle": "2025-01-25T18:39:05.468579Z",
     "shell.execute_reply": "2025-01-25T18:39:05.467760Z",
     "shell.execute_reply.started": "2025-01-25T18:39:05.460601Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# torch.save(model, \"attention_1024.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I5BLw1Ir1ZTT"
   },
   "source": [
    "# Test Your Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VRLjZzBMtCdA"
   },
   "source": [
    "## TODO4: Test your model on 5 examples of your choice including your name!\n",
    "\n",
    "Example Output:\n",
    "```\n",
    "prayutthatha</s></s>aa</s></s>a</s>\n",
    "somchai</s></s></s></s>a</s></s>a</s></s></s></s></s>\n",
    "thanathon</s></s></s></s></s></s></s></s></s></s></s>\n",
    "newin</s>i</s></s></s></s></s></s></s></s></s></s></s></s></s>\n",
    "suthep</s>he</s></s></s></s></s></s></s></s></s></s></s>\n",
    "prawit</s></s></s></s></s></s></s></s></s></s></s></s></s></s>\n",
    "chatchachatti</s></s>i</s></s></s></s>\n",
    "```\n",
    "\n",
    "<font color='blue'>Paste your model predictions in MyCourseVille</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T18:39:07.447374Z",
     "iopub.status.busy": "2025-01-25T18:39:07.447054Z",
     "iopub.status.idle": "2025-01-25T18:39:07.452056Z",
     "shell.execute_reply": "2025-01-25T18:39:07.451168Z",
     "shell.execute_reply.started": "2025-01-25T18:39:07.447312Z"
    },
    "id": "6stNACsUP9h-",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "EXAMPLES = ['ประยุทธ','สมชาย','ธนาธร','เนวิน','สุเทพ','ประวิตร์','ชัชชาติ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T18:39:08.406292Z",
     "iopub.status.busy": "2025-01-25T18:39:08.405984Z",
     "iopub.status.idle": "2025-01-25T18:39:08.412629Z",
     "shell.execute_reply": "2025-01-25T18:39:08.411759Z",
     "shell.execute_reply.started": "2025-01-25T18:39:08.406267Z"
    },
    "id": "kbolC8XIhR3t",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AttentionModel(\n",
       "  (criterion): CrossEntropyLoss()\n",
       "  (lstm): LSTM(65, 32, batch_first=True, bidirectional=True)\n",
       "  (decoder_lstm_cell): LSTMCell(32, 64)\n",
       "  (output_layer): Linear(in_features=64, out_features=24, bias=True)\n",
       "  (fc1): Linear(in_features=96, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T18:39:12.495111Z",
     "iopub.status.busy": "2025-01-25T18:39:12.494795Z",
     "iopub.status.idle": "2025-01-25T18:39:12.502275Z",
     "shell.execute_reply": "2025-01-25T18:39:12.501533Z",
     "shell.execute_reply.started": "2025-01-25T18:39:12.495087Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "EXAMPLES.append('ชนาธิป')\n",
    "predict_data = [torch.tensor(input_encode(name)) for name in EXAMPLES]\n",
    "predict_data = nn.utils.rnn.pad_sequence(predict_data, batch_first=True, padding_value=0)\n",
    "\n",
    "def collate_fn(batch, num_classes=len(input_stoi)):\n",
    "    one_hot_x = torch.stack([F.one_hot(b[\"x\"], num_classes=num_classes) for b in batch])\n",
    "    return {\"x\": one_hot_x.float()}\n",
    "predict_dataset = NameDataset(\n",
    "    predict_data, torch.tensor([torch.tensor(0)] * len(predict_data))\n",
    ")\n",
    "predict_loader = DataLoader(\n",
    "    predict_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn, num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T18:39:14.168481Z",
     "iopub.status.busy": "2025-01-25T18:39:14.168146Z",
     "iopub.status.idle": "2025-01-25T18:39:14.301040Z",
     "shell.execute_reply": "2025-01-25T18:39:14.300364Z",
     "shell.execute_reply.started": "2025-01-25T18:39:14.168454Z"
    },
    "id": "LsN71S9uQ9wo",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 4050 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdemonstem\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b16d2898d02b4c9b8d9dce440e8b09d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011288888888884685, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20250126_152555-u8beluvo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/demonstem/hw3.1_attention/runs/u8beluvo' target=\"_blank\">run3</a></strong> to <a href='https://wandb.ai/demonstem/hw3.1_attention' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/demonstem/hw3.1_attention' target=\"_blank\">https://wandb.ai/demonstem/hw3.1_attention</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/demonstem/hw3.1_attention/runs/u8beluvo' target=\"_blank\">https://wandb.ai/demonstem/hw3.1_attention/runs/u8beluvo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\Tonza\\anaconda3\\envs\\pattern\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d42b9ecca60469bb10f84c9521e4579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prayuttha<PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "somchai<PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "thanathon<PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "newin<PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "suthep<PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "prawit<PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "chatchachattii<PAD><PAD><PAD><PAD><PAD>\n",
      "chonathip<PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n"
     ]
    }
   ],
   "source": [
    "output = trainer.predict(model, predict_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7o3893RL1ZT8"
   },
   "source": [
    "## TODO 5: Show your visualization of attention scores on one of your example\n",
    "\n",
    "<font color='blue'>Paste your visualization image in MyCourseVille</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T18:39:24.001293Z",
     "iopub.status.busy": "2025-01-25T18:39:24.000997Z",
     "iopub.status.idle": "2025-01-25T18:39:24.007650Z",
     "shell.execute_reply": "2025-01-25T18:39:24.006754Z",
     "shell.execute_reply.started": "2025-01-25T18:39:24.001271Z"
    },
    "id": "WHysSqYJ1ZUA",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T18:39:26.204139Z",
     "iopub.status.busy": "2025-01-25T18:39:26.203838Z",
     "iopub.status.idle": "2025-01-25T18:39:26.208694Z",
     "shell.execute_reply": "2025-01-25T18:39:26.207816Z",
     "shell.execute_reply.started": "2025-01-25T18:39:26.204118Z"
    },
    "id": "XdktVnMv1ZTh",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "prediction, attention_scores = zip(*output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T18:39:29.939660Z",
     "iopub.status.busy": "2025-01-25T18:39:29.939295Z",
     "iopub.status.idle": "2025-01-25T18:39:29.978939Z",
     "shell.execute_reply": "2025-01-25T18:39:29.977813Z",
     "shell.execute_reply.started": "2025-01-25T18:39:29.939635Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sample_pred = prediction[-1]\n",
    "sample_pred = [token for token in sample_pred.cpu().numpy().tolist()[-1] if token != 0]  # Remove padding tokens\n",
    "sample_attention_scores = attention_scores[-1]\n",
    "attn_viz = torch.stack(sample_attention_scores).squeeze().cpu().numpy()\n",
    "attn_viz = attn_viz[:len(sample_pred), :len(EXAMPLES[-1])]\n",
    "output_text = [char for char in output_decode(sample_pred)]\n",
    "xlabels = [char for char in EXAMPLES[-1]]\n",
    "assert attn_viz.shape[0] == len(output_text)\n",
    "assert attn_viz.shape[1] == len(xlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "execution": {
     "iopub.execute_input": "2025-01-25T18:35:40.312505Z",
     "iopub.status.busy": "2025-01-25T18:35:40.312169Z",
     "iopub.status.idle": "2025-01-25T18:35:40.717735Z",
     "shell.execute_reply": "2025-01-25T18:35:40.716412Z",
     "shell.execute_reply.started": "2025-01-25T18:35:40.312476Z"
    },
    "id": "BF6HD99lYlgQ",
    "outputId": "caaa0716-5b99-43e8-950f-dd0127d0fbb7",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.heatmap(attn_viz, linewidth=0.5)\n",
    "ax.set_yticklabels(output_text,rotation=30)\n",
    "ax.set_xticklabels(xlabels,rotation=60)\n",
    "plt.savefig('viz.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "pattern",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
